Then, the test phase was performed. The test set used, composed by the last 100 samples, 
was not voxelized in order to test model performance on data in its original format.
To be able to achieve this, ad-hoc backpropagation functions were implemented.
Given a pointcloud, these functions attribute directly to each point the predicted label of the
corresponding voxel in the voxelized pointcloud (voxel grid).
With these operations, it was possibile to build the confusion matrix shown in figure \ref{fig:matrix}.
Using the data in this matrix, appropriate performance metrics were computed: Accuracy 0.691,
Precision 0.425, Recall 0.328 and F1-score 0.370.  

The first thing that can be noted is that only a few classes appear among test set pointclouds.
Secondly, it can be noted from the confusion matrix and guessed by the performance metrics, 
that our model is able to correctly classify the most popular classes such as \textit{car},
\textit{road}, \textit{sidewalk}, \textit{building} and \textit{vegetation} 
but lacks in performance for the others. 
However, the obtained results are still acceptable thanks to the great unbalance among point classes.

Using other Open3d functions, we were able to visualize the pointclouds with different colors depending
on their labels. Figure \ref{fig:visual} shows one of the pointclouds with the
correct colors (true labels) and the ones choosen by \textit{VUE-net} (predicted labels).
The observations made previously on performance agree with what can be seen from the images.
In fact, the model correcly predicts road, sidewalks, cars, buildings and vegetation but is not
able to recognize smaller, unpopular areas as the one in orange that corresponds to a fence.